# DataForge Hackathon â€“ AI Context Audit & Behavioral Anomaly Detection

This repository contains solutions for the **DataForge Pre-Evaluation Assignment** conducted by  
E-Summitâ€™26, IIT Roorkee.

We implemented two independent but complementary systems:
 Problem Statement 1 â€“ Self-Auditing Context Engine  
 Problem Statement 2 â€“ Behavioral Anomaly Detection Engine  

Both systems focus on:
- Explainability
- Transparency
- No hard-coded rules
- Data-driven decision making
- CSV audit outputs

---

# ğŸ“‚ Project Structure
DataForge-Hackathon-Solutions
â”‚
â”œâ”€â”€ PS1_Context_Audit
â”‚   â”œâ”€â”€ context_scoring.py
â”‚   â”œâ”€â”€ generate_csv.py
â”‚   â”œâ”€â”€ sample_docs.json
â”‚   â””â”€â”€ output
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ PS2_Behavioral_Anomaly
â”‚   â”œâ”€â”€ generate_db_activity_logs.py
â”‚   â”œâ”€â”€ behavioral_anomaly_engine.py
â”‚   â””â”€â”€ output
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt

---

#  Problem Statement 1 â€“ Self-Auditing Context Engine

## ğŸ¯ Objective
Given a user query and multiple document summaries, automatically determine which documents are relevant and generate a transparent audit report.

## ğŸ§  Approach
1. Load query and documents
2. Text preprocessing
3. TF-IDF vectorization
4. Cosine similarity scoring
5. Threshold filtering
6. Generate explainable CSV audit

## âš™ï¸ Techniques Used
- TF-IDF
- Cosine Similarity
- Threshold-based decision logic
- Explainable scoring

## ğŸ“¤ Output
PS1_Context_Audit/output/PS1_Context_Audit.csv

Contains:
- query
- document_id
- similarity score
- threshold
- decision (Included/Excluded)
- reason


## ğŸ“Š Flowchart â€“ Context Engine
This flowchart shows how the query and documents are processed using TF-IDF,
cosine similarity scoring, threshold filtering, and CSV audit generation.

<img src="assets/PS1_flowchart.jpg" width="900">

#  Problem Statement 2 â€“ Behavioral Anomaly Detection Engine

## ğŸ¯ Objective
Detect abnormal database activity by learning normal user behavior and identifying statistical deviations.

## ğŸ§  Approach
1. Generate database activity logs
2. Group logs by user
3. Learn baseline behavior (average rows scanned)
4. Compute Z-score deviation
5. Calculate risk percentile
6. Flag anomalies
7. Generate anomaly report

## âš™ï¸ Techniques Used
- Statistical modeling
- Z-score anomaly detection
- Percentile risk scoring
- Explainable alerts
- No if-else rule engine

## ğŸ“¤ Output
PS2_Behavioral_Anomaly_Detection/output/PS2_Anomaly_Report.csv

Contains:
- baseline average
- z-score
- risk percentile
- risk level
- flagged (True/False)
- reason

## ğŸ“Š Flowchart â€“ Behavioral Anomaly Detection
This flowchart shows how database logs are analyzed per user, baseline behavior
is learned, z-score is calculated, risk scoring is performed, and suspicious
activities are flagged.

<img src="assets/PS2_flowchart.jpg" width="900">

# â–¶ï¸ How to Run

## Install dependencies
pip install -r requirements.txt

## Run Problem Statement 1
cd PS1_Context_Audit python generate_csv.py

## Run Problem Statement 2
cd PS2_Behavioral_Anomaly_Detection python generate_db_activity_logs.py python behavioral_anomaly_engine.py


# ğŸ’¡ Key Highlights

â€¢Fully explainable decisions  
â€¢No hardcoded rules  
â€¢ Data-driven approach  
â€¢ Modular design  
â€¢Clean folder structure  
â€¢ Reproducible results  
â€¢ Industry-style audit logs  


# ğŸ Submission

This repository is submitted as part of the **DataForge Hackathon pre-evaluation (10% weightage)**.

Both solutions are runnable locally and generate their respective CSV outputs.

---

# ğŸ‘¨â€ğŸ’» Team
Team Name: Neural Forge 
Members: 4

